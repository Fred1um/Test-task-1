{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee3e560-b5ab-49c2-9620-29ee1cdab9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8825171d-1cca-447e-a347-6391f11b2c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from pathlib import Path\n",
    "from typing import Union\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.functions import col, when, expr, lit, concat, to_date, get_json_object, count, desc, asc\n",
    "from pyspark.sql.types import StructType, StructField, StringType, TimestampType, IntegerType, DoubleType\n",
    "from uuid import uuid4\n",
    "import glob\n",
    "import os\n",
    "from datetime import date, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5949e720-c44e-4242-99c0-1e144553cfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_raw_logs(\n",
    "        external_system_name: str,\n",
    "        date: Union[str, date],\n",
    "        raw_logs_path: Union[str, Path],\n",
    "        prepared_logs_path: Union[str, Path]\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Внутри функции должно происходить чтение логов с помощью pyspark,\n",
    "    приведение их к общей схеме и запись в директорию с препарированными логами.\n",
    "    Препарированные логи должны быть сгрупированны по internal_app_id и date\n",
    "    \"\"\"\n",
    "    spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .appName('PrepareRawLogs')\\\n",
    "    .getOrCreate()\n",
    "\n",
    "    system_path = f\"{raw_logs_path}/external_system_{external_system_name}\"\n",
    "    app_dirs = [name for name in os.listdir(system_path) if os.path.isdir(os.path.join(system_path, name))]\n",
    "    app_id = app_dirs[0].split('=')[1]\n",
    "    df = spark.read.parquet(f\"{raw_logs_path}/external_system_{external_system_name}/application_id={app_id}/date={date}\")\n",
    "    log_schema = StructType([\n",
    "        StructField('external_did', StringType(), True),\n",
    "        StructField('event_name', StringType(), True),\n",
    "        StructField('event_datetime', TimestampType(), True),\n",
    "        StructField('event_json', StringType(), True),\n",
    "        StructField('date', TimestampType(), True),\n",
    "        StructField('push_token', StringType(), True),\n",
    "        StructField('ios_ifa', StringType(), True),\n",
    "        StructField('external_profile_id', StringType(), True),\n",
    "        StructField('external_app_id', StringType(), True),\n",
    "        StructField('external_system', StringType(), True),\n",
    "        StructField('internal_app_id', StringType(), True)])\n",
    "    df_new = spark.createDataFrame([], log_schema)\n",
    "    if external_system_name == '1':\n",
    "        app_uuid = '24a7a8f5-35f0-4c3a-9e51-02c7f62f7f06'\n",
    "        df_new = df.select(df[\"device_id\"].alias(\"external_did\"),\n",
    "                       df[\"event_type\"].alias(\"event_name\"),\n",
    "                       df[\"event_time\"].alias(\"event_datetime\"),\n",
    "                       concat(df[\"user_properties\"], df[\"event_properties\"]).alias(\"event_json\"),\n",
    "                       df[\"event_time\"].cast(\"date\").alias(\"date\"),\n",
    "                       get_json_object(col(\"user_properties\"), \"$.registration_id\").alias(\"push_token\"),\n",
    "                       df[\"idfa\"].alias(\"ios_ifa\"),\n",
    "                       df[\"user_id\"].alias(\"external_profile_id\"),\n",
    "                       lit(app_id).alias(\"external_app_id\"),\n",
    "                       df[\"external_system\"],\n",
    "                       lit(app_uuid).alias(\"internal_app_id\"))\n",
    "    elif external_system_name == '2':\n",
    "        app_uuid = '86ff5d12-55db-4bdf-a849-1b685bdff00b'\n",
    "        df_new = df.select(df[\"uniq_device_id\"].alias(\"external_did\"),\n",
    "                       df[\"event_name\"].alias(\"event_name\"),\n",
    "                       df[\"event_datetime\"].alias(\"event_datetime\"),\n",
    "                       df[\"event_json\"],\n",
    "                       df[\"event_datetime\"].cast(\"date\").alias(\"date\"),\n",
    "                       df[\"uniq_device_id\"].alias(\"push_token\"),\n",
    "                       df[\"ios_ifa\"].alias(\"ios_ifa\"),\n",
    "                       df[\"profile_id\"].alias(\"external_profile_id\"),\n",
    "                       lit(app_id).alias(\"external_app_id\"),\n",
    "                       df[\"external_system\"],\n",
    "                       lit(app_uuid).alias(\"internal_app_id\"))\n",
    "    dirs = prepared_logs_path.split('/')\n",
    "    prepared_logs_path = f'{dirs[0]}/{app_uuid}/{dirs[1]}'\n",
    "    df_new.write.parquet(prepared_logs_path)\n",
    "    df_new.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467516fa-edf0-4cee-8617-156a59cb8414",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_system = '2'\n",
    "data_date = date(2023, 1, 7)\n",
    "raw_logs_path = './'\n",
    "prepare_raw_logs(external_system, f'{data_date.strftime(\"%Y-%m-%d\")}', raw_logs_path, f'prepared/{data_date.strftime(\"%Y-%m-%d\")}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
